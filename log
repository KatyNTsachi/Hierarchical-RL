pygame 1.9.4
Hello from the pygame community. https://www.pygame.org/contribute.html
Loading chipmunk for Linux (64bit) [/home/deep7/hierarchy/local/lib/python2.7/site-packages/pymunk/libchipmunk64.so]
Initializing cpSpace - Chipmunk v6.2.0 (Debug Enabled)
Compile with -DNDEBUG defined to disable debug mode and runtime assertion checks
[33mWARN: Environment '<class 'gym_cars.envs.environment.carsEnv'>' has deprecated methods '_step' and '_reset' rather than 'step' and 'reset'. Compatibility code invoked. Set _gym_disable_underscore_compat = True to disable this behavior.[0m
2019-02-22 15:53:06.671073: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-02-22 15:53:06.761383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2019-02-22 15:53:06.761728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8095
pciBusID: 0000:01:00.0
totalMemory: 7.93GiB freeMemory: 7.53GiB
2019-02-22 15:53:06.761740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2019-02-22 15:53:06.961820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-02-22 15:53:06.961851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2019-02-22 15:53:06.961857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2019-02-22 15:53:06.961993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7262 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)
I0222 15:53:06.963485 140018317027136 tf_logging.py:115] Creating DQNAgent agent with the following parameters:
I0222 15:53:06.963733 140018317027136 tf_logging.py:115] 	 gamma: 0.990000
I0222 15:53:06.963784 140018317027136 tf_logging.py:115] 	 update_horizon: 1.000000
I0222 15:53:06.963828 140018317027136 tf_logging.py:115] 	 min_replay_history: 50000
I0222 15:53:06.963865 140018317027136 tf_logging.py:115] 	 update_period: 1
I0222 15:53:06.963902 140018317027136 tf_logging.py:115] 	 target_update_period: 1000
I0222 15:53:06.963942 140018317027136 tf_logging.py:115] 	 epsilon_train: 0.010000
I0222 15:53:06.963978 140018317027136 tf_logging.py:115] 	 epsilon_eval: 0.001000
I0222 15:53:06.964014 140018317027136 tf_logging.py:115] 	 epsilon_decay_period: 1000000
I0222 15:53:06.964050 140018317027136 tf_logging.py:115] 	 tf_device: /gpu:0
I0222 15:53:06.964085 140018317027136 tf_logging.py:115] 	 use_staging: True
I0222 15:53:06.964119 140018317027136 tf_logging.py:115] 	 optimizer: <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f57f80d7e50>
I0222 15:53:06.965378 140018317027136 tf_logging.py:115] Creating a OutOfGraphReplayBuffer replay memory with the following parameters:
I0222 15:53:06.965444 140018317027136 tf_logging.py:115] 	 observation_shape: (84, 84)
I0222 15:53:06.965491 140018317027136 tf_logging.py:115] 	 observation_dtype: <type 'numpy.uint8'>
I0222 15:53:06.965532 140018317027136 tf_logging.py:115] 	 stack_size: 4
I0222 15:53:06.965570 140018317027136 tf_logging.py:115] 	 replay_capacity: 1000000
I0222 15:53:06.965607 140018317027136 tf_logging.py:115] 	 batch_size: 32
I0222 15:53:06.965643 140018317027136 tf_logging.py:115] 	 update_horizon: 1
I0222 15:53:06.965679 140018317027136 tf_logging.py:115] 	 gamma: 0.990000
I0222 15:53:19.359041 140018317027136 tf_logging.py:115] Restoring parameters from ~/hierarchy/Hierarchical-RL/checkpoints/tf_ckpt-86
I0222 15:53:19.414923 140018317027136 tf_logging.py:115] Reloaded checkpoint and will start from iteration 87
I0222 15:53:19.415067 140018317027136 tf_logging.py:115] Beginning training...
I0222 15:53:19.415138 140018317027136 tf_logging.py:115] Starting iteration 87
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -3900.0Steps executed: 3000 Episode length: 1000 Return: -3900.0Steps executed: 4000 Episode length: 1000 Return: -3950.0Steps executed: 5000 Episode length: 1000 Return: -3950.0Steps executed: 6000 Episode length: 1000 Return: -3900.0Steps executed: 7000 Episode length: 1000 Return: -3800.0Steps executed: 8000 Episode length: 1000 Return: -3750.0Steps executed: 9000 Episode length: 1000 Return: -3900.0Steps executed: 10000 Episode length: 1000 Return: -3900.0Steps executed: 11000 Episode length: 1000 Return: -3900.0Steps executed: 12000 Episode length: 1000 Return: -3800.0Steps executed: 13000 Episode length: 1000 Return: -4000.0Steps executed: 14000 Episode length: 1000 Return: -3850.0Steps executed: 15000 Episode length: 1000 Return: -3800.0Steps executed: 16000 Episode length: 1000 Return: -3900.0Steps executed: 17000 Episode length: 1000 Return: -3700.0Steps executed: 18000 Episode length: 1000 Return: -3900.0Steps executed: 19000 Episode length: 1000 Return: -3650.0Steps executed: 20000 Episode length: 1000 Return: -3800.0Steps executed: 21000 Episode length: 1000 Return: -3750.0Steps executed: 22000 Episode length: 1000 Return: -3950.0Steps executed: 23000 Episode length: 1000 Return: -3950.0Steps executed: 24000 Episode length: 1000 Return: -3950.0Steps executed: 25000 Episode length: 1000 Return: -3850.0I0222 16:08:28.402973 140018317027136 tf_logging.py:115] Average undiscounted return per training episode: -3868.00
I0222 16:08:28.403084 140018317027136 tf_logging.py:115] Average training steps per second: 27.50
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -4000.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -3950.0Steps executed: 5000 Episode length: 1000 Return: -4000.0Steps executed: 6000 Episode length: 1000 Return: -4000.0Steps executed: 7000 Episode length: 1000 Return: -4000.0Steps executed: 8000 Episode length: 1000 Return: -3950.0Steps executed: 9000 Episode length: 1000 Return: -4000.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -4000.0Steps executed: 12000 Episode length: 1000 Return: -4000.0Steps executed: 13000 Episode length: 1000 Return: -4000.0I0222 16:14:28.898397 140018317027136 tf_logging.py:115] Average undiscounted return per evaluation episode: -3992.31
I0222 16:16:03.658557 140018317027136 tf_logging.py:115] Starting iteration 88
Steps executed: 1000 Episode length: 1000 Return: -3850.0Steps executed: 2000 Episode length: 1000 Return: -3800.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -3850.0Steps executed: 5000 Episode length: 1000 Return: -3750.0Steps executed: 6000 Episode length: 1000 Return: -3850.0Steps executed: 7000 Episode length: 1000 Return: -3850.0Steps executed: 8000 Episode length: 1000 Return: -3750.0Steps executed: 9000 Episode length: 1000 Return: -4000.0Steps executed: 10000 Episode length: 1000 Return: -3800.0Steps executed: 11000 Episode length: 1000 Return: -3850.0Steps executed: 12000 Episode length: 1000 Return: -3900.0Steps executed: 13000 Episode length: 1000 Return: -3850.0Steps executed: 14000 Episode length: 1000 Return: -3850.0Steps executed: 15000 Episode length: 1000 Return: -3950.0Steps executed: 16000 Episode length: 1000 Return: -3900.0Steps executed: 17000 Episode length: 1000 Return: -3800.0Steps executed: 18000 Episode length: 1000 Return: -3950.0Steps executed: 19000 Episode length: 1000 Return: -3800.0Steps executed: 20000 Episode length: 1000 Return: -3950.0Steps executed: 21000 Episode length: 1000 Return: -3850.0Steps executed: 22000 Episode length: 1000 Return: -3750.0Steps executed: 23000 Episode length: 1000 Return: -3850.0Steps executed: 24000 Episode length: 1000 Return: -3950.0Steps executed: 25000 Episode length: 1000 Return: -3900.0I0222 16:31:07.528198 140018317027136 tf_logging.py:115] Average undiscounted return per training episode: -3864.00
I0222 16:31:07.528309 140018317027136 tf_logging.py:115] Average training steps per second: 27.66
Steps executed: 1000 Episode length: 1000 Return: -3900.0Steps executed: 2000 Episode length: 1000 Return: -3950.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -3850.0Steps executed: 5000 Episode length: 1000 Return: -4000.0Steps executed: 6000 Episode length: 1000 Return: -3900.0Steps executed: 7000 Episode length: 1000 Return: -4000.0Steps executed: 8000 Episode length: 1000 Return: -3950.0Steps executed: 9000 Episode length: 1000 Return: -3950.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -3950.0Steps executed: 12000 Episode length: 1000 Return: -3950.0Steps executed: 13000 Episode length: 1000 Return: -4000.0I0222 16:37:08.082568 140018317027136 tf_logging.py:115] Average undiscounted return per evaluation episode: -3953.85
I0222 16:38:42.988563 140018317027136 tf_logging.py:115] Starting iteration 89
Steps executed: 1000 Episode length: 1000 Return: -3900.0Steps executed: 2000 Episode length: 1000 Return: -3850.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -3850.0Steps executed: 5000 Episode length: 1000 Return: -3950.0Steps executed: 6000 Episode length: 1000 Return: -3700.0Steps executed: 7000 Episode length: 1000 Return: -3750.0Steps executed: 8000 Episode length: 1000 Return: -3850.0Steps executed: 9000 Episode length: 1000 Return: -3850.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -4000.0Steps executed: 12000 Episode length: 1000 Return: -3900.0Steps executed: 13000 Episode length: 1000 Return: -3800.0Steps executed: 14000 Episode length: 1000 Return: -3850.0Steps executed: 15000 Episode length: 1000 Return: -3950.0Steps executed: 16000 Episode length: 1000 Return: -3900.0Steps executed: 17000 Episode length: 1000 Return: -3900.0Steps executed: 18000 Episode length: 1000 Return: -3900.0Steps executed: 19000 Episode length: 1000 Return: -3850.0Steps executed: 20000 Episode length: 1000 Return: -3900.0Steps executed: 21000 Episode length: 1000 Return: -3900.0Steps executed: 22000 Episode length: 1000 Return: -3900.0Steps executed: 23000 Episode length: 1000 Return: -3800.0Steps executed: 24000 Episode length: 1000 Return: -4000.0Steps executed: 25000 Episode length: 1000 Return: -3850.0I0222 16:53:47.461874 140018317027136 tf_logging.py:115] Average undiscounted return per training episode: -3884.00
I0222 16:53:47.461983 140018317027136 tf_logging.py:115] Average training steps per second: 27.64
Steps executed: 1000 Episode length: 1000 Return: -3950.0Steps executed: 2000 Episode length: 1000 Return: -4000.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -3900.0Steps executed: 5000 Episode length: 1000 Return: -4000.0Steps executed: 6000 Episode length: 1000 Return: -4000.0Steps executed: 7000 Episode length: 1000 Return: -3900.0Steps executed: 8000 Episode length: 1000 Return: -4000.0Steps executed: 9000 Episode length: 1000 Return: -4000.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -3950.0Steps executed: 12000 Episode length: 1000 Return: -4000.0Steps executed: 13000 Episode length: 1000 Return: -4000.0I0222 16:59:48.106791 140018317027136 tf_logging.py:115] Average undiscounted return per evaluation episode: -3976.92
I0222 17:01:22.838757 140018317027136 tf_logging.py:115] Starting iteration 90
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -3850.0Steps executed: 3000 Episode length: 1000 Return: -3900.0Steps executed: 4000 Episode length: 1000 Return: -3900.0Steps executed: 5000 Episode length: 1000 Return: -3900.0Steps executed: 6000 Episode length: 1000 Return: -3950.0Steps executed: 7000 Episode length: 1000 Return: -3800.0Steps executed: 8000 Episode length: 1000 Return: -3650.0Steps executed: 9000 Episode length: 1000 Return: -3900.0Steps executed: 10000 Episode length: 1000 Return: -3850.0Steps executed: 11000 Episode length: 1000 Return: -3950.0Steps executed: 12000 Episode length: 1000 Return: -3800.0Steps executed: 13000 Episode length: 1000 Return: -3950.0Steps executed: 14000 Episode length: 1000 Return: -3950.0Steps executed: 15000 Episode length: 1000 Return: -3800.0Steps executed: 16000 Episode length: 1000 Return: -4000.0Steps executed: 17000 Episode length: 1000 Return: -3750.0Steps executed: 18000 Episode length: 1000 Return: -4000.0Steps executed: 19000 Episode length: 1000 Return: -3900.0Steps executed: 20000 Episode length: 1000 Return: -3850.0Steps executed: 21000 Episode length: 1000 Return: -3950.0Steps executed: 22000 Episode length: 1000 Return: -3950.0Steps executed: 23000 Episode length: 1000 Return: -3900.0Steps executed: 24000 Episode length: 1000 Return: -4000.0Steps executed: 25000 Episode length: 1000 Return: -4000.0I0222 17:16:26.819905 140018317027136 tf_logging.py:115] Average undiscounted return per training episode: -3898.00
I0222 17:16:26.820019 140018317027136 tf_logging.py:115] Average training steps per second: 27.66
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -3950.0Steps executed: 3000 Episode length: 1000 Return: -4000.0Steps executed: 4000 Episode length: 1000 Return: -4000.0Steps executed: 5000 Episode length: 1000 Return: -4000.0Steps executed: 6000 Episode length: 1000 Return: -4000.0Steps executed: 7000 Episode length: 1000 Return: -4000.0Steps executed: 8000 Episode length: 1000 Return: -4000.0Steps executed: 9000 Episode length: 1000 Return: -4000.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -4000.0Steps executed: 12000 Episode length: 1000 Return: -4000.0Steps executed: 13000 Episode length: 1000 Return: -4000.0I0222 17:22:26.993485 140018317027136 tf_logging.py:115] Average undiscounted return per evaluation episode: -3996.15
I0222 17:24:01.768368 140018317027136 tf_logging.py:115] Starting iteration 91
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -3900.0Steps executed: 3000 Episode length: 1000 Return: -3800.0Steps executed: 4000 Episode length: 1000 Return: -4000.0Steps executed: 5000 Episode length: 1000 Return: -3900.0Steps executed: 6000 Episode length: 1000 Return: -3950.0Steps executed: 7000 Episode length: 1000 Return: -3850.0Steps executed: 8000 Episode length: 1000 Return: -3850.0Steps executed: 9000 Episode length: 1000 Return: -3750.0Steps executed: 10000 Episode length: 1000 Return: -3950.0Steps executed: 11000 Episode length: 1000 Return: -3900.0Steps executed: 12000 Episode length: 1000 Return: -4000.0Steps executed: 13000 Episode length: 1000 Return: -3600.0Steps executed: 14000 Episode length: 1000 Return: -3950.0Steps executed: 15000 Episode length: 1000 Return: -3850.0Steps executed: 16000 Episode length: 1000 Return: -3950.0Steps executed: 17000 Episode length: 1000 Return: -3950.0Steps executed: 18000 Episode length: 1000 Return: -3700.0Steps executed: 19000 Episode length: 1000 Return: -3950.0Steps executed: 20000 Episode length: 1000 Return: -3950.0Steps executed: 21000 Episode length: 1000 Return: -3750.0Steps executed: 22000 Episode length: 1000 Return: -3950.0Steps executed: 23000 Episode length: 1000 Return: -3850.0Steps executed: 24000 Episode length: 1000 Return: -3850.0Steps executed: 25000 Episode length: 1000 Return: -3850.0I0222 17:39:05.548089 140018317027136 tf_logging.py:115] Average undiscounted return per training episode: -3880.00
I0222 17:39:05.548197 140018317027136 tf_logging.py:115] Average training steps per second: 27.66
Steps executed: 1000 Episode length: 1000 Return: -4000.0Steps executed: 2000 Episode length: 1000 Return: -4000.0Steps executed: 3000 Episode length: 1000 Return: -3950.0Steps executed: 4000 Episode length: 1000 Return: -4000.0Steps executed: 5000 Episode length: 1000 Return: -4000.0Steps executed: 6000 Episode length: 1000 Return: -4000.0Steps executed: 7000 Episode length: 1000 Return: -4000.0Steps executed: 8000 Episode length: 1000 Return: -4000.0Steps executed: 9000 Episode length: 1000 Return: -4000.0Steps executed: 10000 Episode length: 1000 Return: -4000.0Steps executed: 11000 Episode length: 1000 Return: -4000.0Steps executed: 12000 Episode length: 1000 Return: -4000.0Steps executed: 13000 Episode length: 1000 Return: -4000.0I0222 17:45:06.551328 140018317027136 tf_logging.py:115] Average undiscounted return per evaluation episode: -3996.15
I0222 17:46:41.204969 140018317027136 tf_logging.py:115] Starting iteration 92
Steps executed: 1000 Episode length: 1000 Return: -3900.0Steps executed: 2000 Episode length: 1000 Return: -3850.0Steps executed: 3000 Episode length: 1000 Return: -3850.0Steps executed: 4000 Episode length: 1000 Return: -3950.0Steps executed: 5000 Episode length: 1000 Return: -3950.0Steps executed: 6000 Episode length: 1000 Return: -3850.0Steps executed: 7000 Episode length: 1000 Return: -3950.0Steps executed: 8000 Episode length: 1000 Return: -3900.0Steps executed: 9000 Episode length: 1000 Return: -3900.0Steps executed: 10000 Episode length: 1000 Return: -3950.0Steps executed: 11000 Episode length: 1000 Return: -3900.0Steps executed: 12000 Episode length: 1000 Return: -3850.0Steps executed: 13000 Episode length: 1000 Return: -3900.0Steps executed: 14000 Episode length: 1000 Return: -3850.0Steps executed: 15000 Episode length: 1000 Return: -3900.0Steps executed: 16000 Episode length: 1000 Return: -3750.0Steps executed: 17000 Episode length: 1000 Return: -3950.0Steps executed: 18000 Episode length: 1000 Return: -4000.0Steps executed: 19000 Episode length: 1000 Return: -3950.0Steps executed: 20000 Episode length: 1000 Return: -3850.0